{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Google Colab SETUP ONLY (LOCAL BELOW)\n",
    "\n",
    "Only run the next 2 blocks in Google Colab"
   ],
   "id": "5066d4af2bf6bf49"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install pdfplumber beautifulsoup4 python-docx python-dotenv",
   "id": "f79c06301996a22d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import traceback\n",
    "import pdfplumber\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from docx import Document\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import files\n",
    "\n",
    "    # Upload your .env file\n",
    "    uploaded = files.upload()  # This will prompt you to upload your .env file\n",
    "\n",
    "    # Format the date as \"Month Day, Year\", e.g. \"May 15, 2024\"\n",
    "    APPLICATION_DATE = datetime.now().strftime(\"%B %d, %Y\")\n",
    "    print(\"Application Date:\", APPLICATION_DATE)\n",
    "\n",
    "    # Now load the environment variables from the .env file\n",
    "    load_dotenv()\n",
    "\n",
    "    # Verify that the variables are loaded\n",
    "    import os\n",
    "    print(\"OPENAI_API_KEY:\", repr(os.getenv(\"OPENAI_API_KEY\")))\n",
    "    print(\"NAME:\", os.getenv(\"NAME\"))\n",
    "    print(\"Google Colab setup complete.\")\n",
    "else:\n",
    "    print(\"This block should only be run in Google Colab.\")"
   ],
   "id": "a395a23038c774ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## LOCAL SETUP ONLY\n",
    "\n",
    "Skip this cell if you are using Google Colab.\n",
    "This cell loads the necessary modules and environment variables."
   ],
   "id": "d7f5473c32aba1fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Copy the following command into your CLI:\n",
    "\n",
    "pip install pdfplumber beautifulsoup4 python-docx python-dotenv langchain langchain-openai"
   ],
   "id": "9c3f051222ae3882"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import traceback\n",
    "import pdfplumber\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from docx import Document\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "from datetime import datetime\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Format the date as \"Month Day, Year\", e.g. \"May 15, 2024\"\n",
    "APPLICATION_DATE = datetime.now().strftime(\"%B %d, %Y\")\n",
    "print(\"Application Date:\", APPLICATION_DATE)\n",
    "\n",
    "# Set OpenAI API key\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\").strip()\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"⚠️ OpenAI API Key is missing or invalid!\")\n",
    "\n",
    "\n",
    "# Personal Details\n",
    "NAME = os.getenv(\"NAME\", \"Greg Barker\")\n",
    "ADDRESS = os.getenv(\"ADDRESS\", \"[Your Address]\")\n",
    "CITY_STATE_ZIP = os.getenv(\"CITY_STATE_ZIP\", \"[City, State, Zip]\")\n",
    "EMAIL = os.getenv(\"EMAIL\", \"gregcbarker@gmail.com\")\n",
    "PHONE = os.getenv(\"PHONE\", \"+1 403-828-9041\")\n",
    "GITHUB = os.getenv(\"GITHUB\", \"https://github.com/savevsgames\")\n",
    "LINKEDIN = os.getenv(\"LINKEDIN\", \"https://www.linkedin.com/in/greg-barker-savevsgames/\")\n",
    "\n",
    "print(NAME, ADDRESS, CITY_STATE_ZIP, EMAIL, PHONE, GITHUB, LINKEDIN, sep=\"\\n\")\n",
    "print(\"✅ Setup complete!\")\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "repr(OPENAI_API_KEY)",
   "id": "1452a0006c2ede98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Initialize LLM Model with LangChain\n",
    "\n",
    "- This cell instantiates the model once so that all subsequent calls can use it.\n",
    "- All utility functions will use this instance."
   ],
   "id": "be06e9e75816a2d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "# Instantiate the ChatOpenAI model with desired parameters\n",
    "model = ChatOpenAI(temperature=0, api_key=OPENAI_API_KEY.strip(), stream_usage=True)\n",
    "print(\"✅ LLM model instantiated.\")\n",
    "\n",
    "# Test call: Check connection and print basic model info\n",
    "try:\n",
    "    test_response = model.invoke([\n",
    "        SystemMessage(content=\"Connection test: You are a helpful connection tester.\"),\n",
    "        HumanMessage(content=\"Please return your model name and confirm your connection status.\")\n",
    "    ])\n",
    "    print(\"✅ Test call successful. Response:\")\n",
    "    print(test_response.content)\n",
    "except Exception as e:\n",
    "    print(\"⚠️ Error during LLM test call:\")\n",
    "    print(traceback.format_exc())"
   ],
   "id": "fa085e299c4c3dab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Utility Functions\n",
    "\n",
    "This cell defines helper functions for user interaction, file extraction, web scraping, OpenAI calls, and saving the output."
   ],
   "id": "23e2e989307a5985"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def print_markdown(message):\n",
    "    \"\"\"Utility function to display markdown messages in the notebook.\"\"\"\n",
    "    display(Markdown(message))\n",
    "\n",
    "\n",
    "# --- User Input Helpers ---\n",
    "def select_job_source():\n",
    "    \"\"\"\n",
    "    Prompts the user to enter the number corresponding to the job source.\n",
    "    (Assumes that the available job sources have already been printed.)\n",
    "    \"\"\"\n",
    "    job_sources = [\n",
    "        \"Indeed\", \"LinkedIn\", \"Glassdoor\", \"JobBank.ca\", \"AngelList\",\n",
    "        \"Stack Overflow Jobs\", \"WeWorkRemotely\", \"Referred by Friend\",\n",
    "        \"Company Website\", \"Other\"\n",
    "    ]\n",
    "    while True:\n",
    "        choice = input(\"Enter the number corresponding to the job source: \")\n",
    "        if choice.isdigit() and 1 <= int(choice) <= len(job_sources):\n",
    "            return job_sources[int(choice) - 1]\n",
    "        print(\"❌ Invalid choice. Please enter a number from the list.\")\n",
    "\n",
    "\n",
    "def get_user_inputs():\n",
    "    \"\"\"Prompts the user for job-related inputs.\"\"\"\n",
    "    # Now ask for the job source (after the options have been printed in above cell)\n",
    "    job_source = select_job_source()\n",
    "\n",
    "    print_markdown(\"### Paste the full job posting text below:\")\n",
    "\n",
    "    job_posting = input(\"Job Posting: \")\n",
    "\n",
    "    company_website = input(\"Enter the company website (or press Enter to skip): \")\n",
    "\n",
    "    context_links = []\n",
    "    print(\"Enter up to 3 additional research links (press Enter to skip each one):\")\n",
    "    for i in range(3):\n",
    "        link = input(f\"Link {i + 1}: \")\n",
    "        if link:\n",
    "            context_links.append(link)\n",
    "\n",
    "\n",
    "    return job_posting, company_website, context_links, job_source\n",
    "\n",
    "\n",
    "# --- PDF Extraction ---\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from a PDF resume, truncating to 2000 characters.\"\"\"\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"⚠️ PDF not found at: {pdf_path}\")\n",
    "        return \"\"\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "    return text.strip()\n",
    "\n",
    "# --- LLM-Token Tracking Function ---\n",
    "def print_token_usage(response):\n",
    "    # Try usage_metadata first\n",
    "    if hasattr(response, \"usage_metadata\") and response.usage_metadata:\n",
    "        print(\"Token usage:\", response.usage_metadata)\n",
    "    # Otherwise, try checking response_metadata for token_usage\n",
    "    elif hasattr(response, \"response_metadata\") and response.response_metadata.get(\"token_usage\"):\n",
    "        print(\"Token usage:\", response.response_metadata[\"token_usage\"])\n",
    "    else:\n",
    "        print(\"Token usage information not available.\")\n",
    "\n",
    "\n",
    "# --- LLM-Powered Functions using the global model ---\n",
    "def process_job_posting(job_posting_text):\n",
    "    \"\"\"\n",
    "    Extracts the company name and summarizes the job posting using the global model.\n",
    "    Expected output format (as generated by the LLM):\n",
    "\n",
    "    Company Name: [Extracted Company Name]\n",
    "    Job Summary: [Concise Job Summary]\n",
    "    \"\"\"\n",
    "    # Limit the posting to the first 2000 characters to avoid token issues.\n",
    "    truncated_posting = job_posting_text[:3000]\n",
    "    prompt = f\"\"\"\n",
    "You are a skilled job assistant.\n",
    "\n",
    "The user has provided the following job posting text:\n",
    "---\n",
    "{truncated_posting}\n",
    "---\n",
    "\n",
    "Tasks:\n",
    "1. Extract the company name.\n",
    "2. Summarize the job posting concisely with all key details required to find the right candidate (include qualifications, required skills, and other relevant job details).\n",
    "\n",
    "Output in the following format:\n",
    "Company Name: [Extracted Company Name]\n",
    "Job Summary: [Concise Job Summary]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = model.invoke([\n",
    "            SystemMessage(content=\"You are a skilled job assistant.\"),\n",
    "            HumanMessage(content=prompt)\n",
    "        ])\n",
    "        print_token_usage(response)\n",
    "        result = response.content\n",
    "        print(\"LLM output for job posting processing:\")\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ LLM error in process_job_posting:\")\n",
    "        print(traceback.format_exc())\n",
    "        return \"Generic\", \"\"\n",
    "\n",
    "    # Parse the response using simple string splits.\n",
    "    company_name = \"Generic\"\n",
    "    job_summary = \"\"\n",
    "\n",
    "    if \"Company Name:\" in result:\n",
    "        # Extract text from the first occurrence of \"Company Name:\" up to the next newline.\n",
    "        company_name = result.split(\"Company Name:\", 1)[1].split(\"\\n\")[0].strip()\n",
    "\n",
    "    if \"Job Summary:\" in result:\n",
    "        # Everything after \"Job Summary:\" is considered the summary.\n",
    "        job_summary = result.split(\"Job Summary:\", 1)[1].strip()\n",
    "\n",
    "    return company_name, job_summary\n",
    "\n",
    "\n",
    "\n",
    "def generate_cover_letter(resume_text, job_summary, company_info, context_info, job_source, company_name, NAME, EMAIL, ADDRESS, CITY_STATE_ZIP, PHONE, GITHUB, LINKEDIN, APPLICATION_DATE):\n",
    "    \"\"\"Generates a personalized cover letter using the global model.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are an expert cover letter writer.\n",
    "\n",
    "Date for Cover Letter:\n",
    "- Date: {APPLICATION_DATE}\n",
    "\n",
    "Candidate Details:\n",
    "- Name: {NAME}\n",
    "- Email: {EMAIL}\n",
    "- Phone: {PHONE}\n",
    "- Address: {ADDRESS}\n",
    "- City/State/Postal-ZIP: {CITY_STATE_ZIP}\n",
    "- GitHub: {GITHUB}\n",
    "- LinkedIn: {LINKEDIN}\n",
    "\n",
    "Resume:\n",
    "- Full Resume: {resume_text}\n",
    "\n",
    "Job Posting Details:\n",
    "- Company: {company_name}\n",
    "- Job Source: {job_source}\n",
    "- Job Summary: {job_summary}\n",
    "Company Info:\n",
    "{company_info[:2000]}... (truncated)\n",
    "\n",
    "Additional Context:\n",
    "{context_info[:2000]}... (truncated)\n",
    "\n",
    "Instructions:\n",
    "- DO NOT USE GENERIC PLACEHOLDERS.\n",
    "- Replace ALL placeholder text with the candidate’s actual details as provided (Example: no [ ] placeholder tags).\n",
    "- IF ANY OF THE CONTEXT OR SUMMARY DATA IS RELATED TO SECURITY(https), LOG-IN, SIGN-UP INFORMATION, ETC. YOU ARE TO IGNORE THE CONTEXT THAT REFERS TO THESE DETAILS AND PARSE IT FROM THE GENERATED RESPONSE. THIS DOES NOT INCLUDE THE USER'S DETAILS (NAME, EMAIL, ADDRESS, CITY_STATE_ZIP, PHONE, GITHUB, LINKEDIN) OR THE CURRENT TIME; THOSE SHOULD BE INCLUDED IN THE RESPONSE.\n",
    "- Use the context carefully and only when it aligns with the job description (Example: A Web Developer job posting for an Oil & Gas company will not be looking for someone to work on a drilling crew, they will be looking for a web developer, but the company's website may inform users of their drilling operations). This type of context CAN and SHOULD be used to better inform you about the company's values and industry/specializations. This can then be used where it is relevant to the job posting to build a better cover letter.\n",
    "- Generate a concise, high-quality cover letter tailored for the candidate and the job.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = model.invoke([\n",
    "            SystemMessage(content=\"You are an expert cover letter writer.\"),\n",
    "            HumanMessage(content=prompt)\n",
    "        ])\n",
    "        print_token_usage(response)\n",
    "        result = response.content\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ LLM error in generate_cover_letter:\")\n",
    "        print(traceback.format_exc())\n",
    "        return \"\"\n",
    "    return result\n",
    "\n",
    "\n",
    "# --- Scraping & Summarization ---\n",
    "def scrape_web_content(url):\n",
    "    \"\"\"Scrapes text content from a URL, truncated to 2000 characters.\"\"\"\n",
    "    if not url:\n",
    "        return \"\"\n",
    "    if not url.startswith((\"http://\", \"https://\")):\n",
    "        url = \"https://\" + url\n",
    "    try:\n",
    "        response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        return soup.get_text(separator=\"\\n\")[:2000]\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Failed to scrape {url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def summarize_scraped_content(text, title=\"Scraped Content Summary\"):\n",
    "    \"\"\"\n",
    "    Uses the global model to generate a concise summary of the given text.\n",
    "    Prints the summary and returns it.\n",
    "    \"\"\"\n",
    "    if text.strip():\n",
    "        prompt = f\"Please summarize the following text in a concise manner:\\n\\n{text}\"\n",
    "        try:\n",
    "            response = model.invoke([HumanMessage(content=prompt)])\n",
    "            print_token_usage(response)\n",
    "            summary = response.content\n",
    "            print(f\"✅ {title}:\\n{summary}\\n\")\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error summarizing {title}:\")\n",
    "            print(traceback.format_exc())\n",
    "            return text\n",
    "    else:\n",
    "        print(f\"⚠️ No content available for {title}.\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# --- Saving Output ---\n",
    "def sanitize_filename(name):\n",
    "    \"\"\"Sanitizes a string for use as a filename.\"\"\"\n",
    "    return re.sub(r'[^a-zA-Z0-9_\\-]', '_', name)\n",
    "\n",
    "\n",
    "def save_as_docx(cover_letter, company_name):\n",
    "    \"\"\"Saves the cover letter as a DOCX file in an output directory, overwriting if it exists.\"\"\"\n",
    "    output_dir = \"./output\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    safe_company = sanitize_filename(company_name) or \"Generic\"\n",
    "    filename = os.path.join(output_dir, f\"CoverLetter-{safe_company}.docx\")\n",
    "\n",
    "    # Explicitly remove the file if it exists\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "\n",
    "    doc = Document()\n",
    "    doc.add_paragraph(cover_letter)\n",
    "    doc.save(filename)\n",
    "    print(f\"✅ Cover letter saved as: {os.path.abspath(filename)}\")\n"
   ],
   "id": "d5728e21e2afde6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Print Available Job Sources\n",
    "\n",
    "Below are the available job sources. Please note the numbers as you will need them when prompted."
   ],
   "id": "6bb37b517fc08099"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "job_sources = [\n",
    "    \"Indeed\", \"LinkedIn\", \"Glassdoor\", \"JobBank.ca\", \"AngelList\",\n",
    "    \"Stack Overflow Jobs\", \"WeWorkRemotely\", \"Referred by Friend\",\n",
    "    \"Company Website\", \"Other\"\n",
    "]\n",
    "for i, source in enumerate(job_sources, 1):\n",
    "    print(f\"{i}. {source}\")"
   ],
   "id": "eb54d3dd8ce2ece2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Gather User Inputs\n",
    "\n",
    "Run this cell and follow the prompts to paste the job posting, enter the company website,\n",
    "add up to 3 research links, and select the job source."
   ],
   "id": "94748e17717d04cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "job_posting, company_website, context_links, job_source = get_user_inputs()\n",
    "print(\"\\n✅ User inputs collected!\")"
   ],
   "id": "9a3102ff9dc468dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Extract Resume Text\n",
    "\n",
    "This cell extracts your resume text from the specified PDF file."
   ],
   "id": "fd2a2836f039bd35"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "resume_pdf_path = \"./resume/GregBarkerResume2025.pdf\"\n",
    "resume_text = extract_text_from_pdf(resume_pdf_path)\n",
    "if resume_text:\n",
    "    print(\"✅ Resume text extracted.\")\n",
    "else:\n",
    "    print(\"⚠️ Resume text extraction failed or PDF not found.\")"
   ],
   "id": "b5e0aa93ad88417",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Process Job Posting\n",
    "\n",
    "This cell uses OpenAI to extract the company name and a summary of the job posting.\n"
   ],
   "id": "e8b1eb44d06958bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "company_name, job_summary = process_job_posting(job_posting)\n",
    "print(f\"✅ Extracted Company Name: {company_name}\")\n",
    "print(f\"✅ Job Summary: {job_summary}\")"
   ],
   "id": "642b3622ad4226ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Scrape Company & Context Info\n",
    "\n",
    "This cell scrapes additional details from the company website and any provided research links.\n"
   ],
   "id": "b7cfe5ce8f4875ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Scrape raw content\n",
    "company_info_raw = scrape_web_content(company_website) if company_website else \"\"\n",
    "context_info_raw = \"\\n\".join([scrape_web_content(link) for link in context_links])\n",
    "\n",
    "# Print raw scraped content (optional)\n",
    "print(\"✅ Raw Company Info Scraped:\\n\", company_info_raw[:500], \"\\n...\")\n",
    "print(\"✅ Raw Context Info Scraped:\\n\", context_info_raw[:500], \"\\n...\")\n",
    "\n",
    "# Summarize the scraped content using the LLM\n",
    "company_info = summarize_scraped_content(company_info_raw, \"Company Info Summary\")\n",
    "context_info = summarize_scraped_content(context_info_raw, \"Context Info Summary\")\n",
    "\n",
    "print(\"✅ Web scraping and summarization complete.\")"
   ],
   "id": "808bff2db5cb0e16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Generate Cover Letter\n",
    "\n",
    "This cell generates a personalized cover letter using the gathered information and OpenAI.\n"
   ],
   "id": "5e778f29b69dc6a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cover_letter = generate_cover_letter(\n",
    "    resume_text, job_summary, company_info, context_info, job_source, company_name, NAME, EMAIL, ADDRESS, CITY_STATE_ZIP, PHONE, GITHUB, LINKEDIN, APPLICATION_DATE\n",
    ")\n",
    "if cover_letter:\n",
    "    print(\"✅ Cover letter generated. Preview below:\\n\")\n",
    "    print(cover_letter[:2000] + \"\\n...\")  # Print first 500 characters as a preview\n",
    "else:\n",
    "    print(\"⚠️ Cover letter generation failed.\")"
   ],
   "id": "410597b346c7c0fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Save Cover Letter\n",
    "\n",
    "This final cell saves your generated cover letter as a DOCX file."
   ],
   "id": "593f73bb020c582a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if cover_letter:\n",
    "    save_as_docx(cover_letter, company_name)\n",
    "else:\n",
    "    print(\"⚠️ No cover letter to save.\")"
   ],
   "id": "482df4628e61d896",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
